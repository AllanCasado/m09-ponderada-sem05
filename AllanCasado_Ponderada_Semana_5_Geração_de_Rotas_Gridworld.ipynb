{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "dnWc8B88TGCf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Definição da classe Gridworld"
      ],
      "metadata": {
        "id": "Bv7FBW5WZZJg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oDLkmhWbmmie"
      },
      "outputs": [],
      "source": [
        "# definição da classe que caracteriza o grid no qual o agente atuará\n",
        "class Gridworld:\n",
        "    # o método construtor recebe o número de linhas 'n' e o número de colunas 'm' do grid\n",
        "    def __init__(self, n, m):\n",
        "        self.grid = [[0 for _ in range(m)] for _ in range(n)] # cria uma matriz com n linhas e m colunas\n",
        "\n",
        "        # inicializa as listas para armazenar as coordenadas das montanhas e\n",
        "        # das areias movediças\n",
        "        self.coordenadas_montanhas = []\n",
        "        self.coordenadas_areias = []\n",
        "\n",
        "        # inicializa os pontos de inicio e chegada que serão definidos pelo usuário\n",
        "        self.inicio = None\n",
        "        self.chegada = None\n",
        "\n",
        "        # inicializa uma matriz que armazenará as recompensas de cada ponto do grid\n",
        "        self.recompensas = [[0 for _ in range(m)] for _ in range(n)]\n",
        "\n",
        "    # método que permite definir as coordenadas das montanhas e areas\n",
        "    def definir_obstaculos(self, coordenadas_montanhas, coordenadas_areias):\n",
        "        # para cada coordenada (x, y) na lista 'coordenadas_montanhas', marca-se\n",
        "        # -1 no grid\n",
        "        self.coordenadas_montanhas = coordenadas_montanhas\n",
        "        for x_montanha, y_montanha in coordenadas_montanhas:\n",
        "            self.grid[y_montanha][x_montanha] = -1\n",
        "\n",
        "        # para cada coordenada (x, y) na lista 'coordenadas_areias', marca-se\n",
        "        # -2 no grid\n",
        "        self.coordenadas_areias = coordenadas_areias\n",
        "        for x_areia, y_areia in coordenadas_areias:\n",
        "            self.grid[y_areia][x_areia] = -2\n",
        "\n",
        "        # -1 e -2 foram escolhidos de maneira arbitraria, apenas para representar\n",
        "        # os pontos que são obstáculos\n",
        "\n",
        "    # método que permite definir os pontos de inicio e chegada,\n",
        "    # que definem onde o agente iniciará e onde ele deve terminar\n",
        "    def definir_inicio_chegada(self, inicio, chegada):\n",
        "        self.inicio = inicio\n",
        "        self.chegada = chegada\n",
        "        x_inicio, y_inicio = inicio\n",
        "        x_chegada, y_chegada = chegada\n",
        "        self.grid[y_inicio][x_inicio] = -3\n",
        "        self.grid[y_chegada][x_chegada] = -4\n",
        "\n",
        "        # apenas marca um -3 na coordenada do inicio e -4 na coordenada\n",
        "        # de chegada. valores escolhidos de maneira arbitria apenas para\n",
        "        # diferenciar os pontos no grid\n",
        "\n",
        "    # método que permite definir as recompensas para cada ponto do grid\n",
        "    def definir_recompensas(self, recompensa_chegada, recompensa_areia, recompensa_montanha, recompensa_padrao):\n",
        "        # inicialmente inicializa todos os pontos do grid com uma recompensa padrão\n",
        "        for y in range(len(self.grid)):\n",
        "            for x in range(len(self.grid[0])):\n",
        "                self.recompensas[y][x] = recompensa_padrao\n",
        "\n",
        "        # atualiza a recompensa do ponto de chegada com o valor recebido\n",
        "        x_chegada, y_chegada = self.chegada\n",
        "        self.recompensas[y_chegada][x_chegada] = recompensa_chegada\n",
        "\n",
        "        # atualiza a recompensa para os pontos que são montanhas ou areias com os valores\n",
        "        # recebidos\n",
        "        for x_areia, y_areia in self.coordenadas_areias:\n",
        "            self.recompensas[y_areia][x_areia] = recompensa_areia\n",
        "        for x_montanha, y_montanha in self.coordenadas_montanhas:\n",
        "            self.recompensas[y_montanha][x_montanha] = recompensa_montanha\n",
        "\n",
        "    # permite visualizar o grid de duas maneiras:\n",
        "    # 1. com cada ponto do grid sendo representado com um símbolo específico\n",
        "    # 2. com cada ponto do grid sendo representado pela recompensa atribuida a esse ponto\n",
        "    # obs: caso seja desejado visualizar a posição do agente é possível passar uma coordenada com a posição dele,\n",
        "    # e nessa coordenada será colocado um 'X'\n",
        "    def visualizar_grid(self, modo=\"simbolos\", pos_agente=None):\n",
        "        # se for desejado visualiza a partir de símbolos, cria-se um dicionário\n",
        "        # que mapeia os números atribuídos a cada ponto do grid para uma letra\n",
        "        # que representa o que cada ponto é\n",
        "        if modo == \"simbolos\":\n",
        "            simbolos = {\n",
        "                0:  '   ',\n",
        "                -1: ' M ', # M - montanha\n",
        "                -2: ' A ', # A - areia\n",
        "                -3: ' I ', # I - inicio\n",
        "                -4: ' C ' # C - chegada\n",
        "            }\n",
        "            # percorre cada posição do grid. se a posição na iteração atual corresponder a posição do agente passada como parâemtro,\n",
        "            # coloca um X nessa posição. se a posição atual não é a do agente, busca-se o valor dessa posição utilizando 'self.grid[y][x]'\n",
        "            # e busca o símbolo correspondente no dicionário definido acima\n",
        "            for y in range(len(self.grid)):\n",
        "                for x in range(len(self.grid[y])):\n",
        "                    if pos_agente == (x, y):\n",
        "                        print(' X |', end=\"\")\n",
        "                    else:\n",
        "                        print(f\"{simbolos.get(self.grid[y][x], ' ? ')}|\", end=\"\")\n",
        "                print(\"\\n\" + \"----\" * len(self.grid[0]))\n",
        "        # se o modo de visualização for a partir das recompensas das posição, apenas itera em todas as posições\n",
        "        # e pega o valor da recompensa de cada posição na matriz \"recompensas\"\n",
        "        elif modo == \"recompensas\":\n",
        "            for y in range(len(self.recompensas)):\n",
        "                for x in range(len(self.recompensas[y])):\n",
        "                    print(f\"{self.recompensas[y][x]: 3} |\", end=\"\")\n",
        "                print(\"\\n\" + \"-----\" * len(self.recompensas[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Definição da classe Agente"
      ],
      "metadata": {
        "id": "Msx_9wLiZeUn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CkKNzFhwmnG2"
      },
      "outputs": [],
      "source": [
        "#define um Agente que pode navegar dentro de um ambiente Gridworld\n",
        "class Agente:\n",
        "    # método construtor recebe a posição inicial do agente\n",
        "    def __init__(self, inicio_pos):\n",
        "\n",
        "        # armazena a posição inicial recebida\n",
        "        self.inicio_pos = inicio_pos\n",
        "\n",
        "        # armazena a posição atual do agente, que inicialmente é igual a\n",
        "        # posição inicial\n",
        "        self.posicao = inicio_pos\n",
        "\n",
        "        # define as ações do agente, junto com a mudança nas coordenadas que cada\n",
        "        # ação ira causar\n",
        "        self.acoes = {'up': (0, -1), 'down': (0, 1), 'left': (-1, 0), 'right': (1, 0)}\n",
        "\n",
        "    # método que permite o agente mover-se dentro do gridworld recebido como argumento.\n",
        "    def mover(self, acao, gridworld):\n",
        "\n",
        "        # verifica-se se a ação recebida é valida\n",
        "        if acao not in self.acoes:\n",
        "            # print(f\"Ação '{acao}' não é válida.\")\n",
        "            return False\n",
        "\n",
        "        # calcula a nova posição do agente somando a mudança de posição\n",
        "        # (dx, dy) correspondente com a ação tomada\n",
        "        dx, dy = self.acoes[acao]\n",
        "        x, y = self.posicao\n",
        "        nova_pos = (x + dx, y + dy)\n",
        "\n",
        "        # verifica se a nova posição é válida, ou seja, se está dentro dos limites\n",
        "        # do grid\n",
        "        x_new, y_new = nova_pos\n",
        "        if x_new < 0 or x_new >= len(gridworld.grid[0]) or y_new < 0 or y_new >= len(gridworld.grid):\n",
        "            # print(\"Movimento fora dos limites do grid.\")\n",
        "            return False\n",
        "\n",
        "        # verifica se a nova posição é uma montanha ou areia.\n",
        "        # se for montanha, o agente permanecerá na posição atual\n",
        "        # se for areia, o agente reiniciará, voltando para a posição inicial\n",
        "        # definida no momento de inicialização do agente\n",
        "        tipo_celula = gridworld.grid[nova_pos[1]][nova_pos[0]]\n",
        "        if tipo_celula == -1:\n",
        "            # print(\"Movimento bloqueado por uma montanha! Permanecendo na posição atual.\")\n",
        "            return False\n",
        "        elif tipo_celula == -2:\n",
        "            # print(\"Capturado por areia movediça! Reiniciando...\")\n",
        "            self.posicao = self.inicio_pos\n",
        "            return False\n",
        "\n",
        "        self.posicao = nova_pos\n",
        "        return True\n",
        "\n",
        "    # retorna a posição atual do agente no grid\n",
        "    def obter_posicao(self):\n",
        "        return self.posicao\n",
        "\n",
        "    # retorna a lista com as ações possívels do agente, ou seja,\n",
        "    # ['up', 'down', 'left', 'right']\n",
        "    def obter_acoes(self):\n",
        "        return list(self.acoes.keys())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Definição da classe GeradorRotas"
      ],
      "metadata": {
        "id": "xQLOqL3mZhMM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# classe que gerencia as rotas percorridas por um agente em um gridworld\n",
        "class GeradorRotas:\n",
        "    # método construtor recebe um gridworld e um agente\n",
        "    def __init__(self, gridworld, agente):\n",
        "        self.gridworld = gridworld\n",
        "        self.agente = agente\n",
        "\n",
        "        # incialização do dicionário que armazenará as rotas cadastradas\n",
        "        self.rotas = {}\n",
        "\n",
        "    # cadastra uma nova rota se ela ainda não existir\n",
        "    def cadastrar_rota(self, nome_rota):\n",
        "        if nome_rota not in self.rotas:\n",
        "            # a rota é basicamente uma lista de coordenadas. toda rota\n",
        "            # é inicializada com a primeira coordenada sendo a posição inicial\n",
        "            # do agente.\n",
        "            self.rotas[nome_rota] = [self.agente.inicio_pos]\n",
        "        else:\n",
        "            print(f\"A rota '{nome_rota} já existe.\")\n",
        "\n",
        "    # atualiza uma rota existente\n",
        "    def atualizar_rota(self, nome_rota):\n",
        "        # se a rota que deseja-se atualizar existir, basicamente\n",
        "        # adiciona-se nela a posição atual do agente\n",
        "        if nome_rota in self.rotas:\n",
        "            self.rotas[nome_rota].append(self.agente.posicao)\n",
        "        else:\n",
        "            print(f\"A rota '{nome_rota}' não foi encontrada.\")\n",
        "\n",
        "    # exibe as coordenadas de uma rota cadastrada\n",
        "    def exibir_rota(self, nome_rota):\n",
        "        if nome_rota in self.rotas:\n",
        "            print(f\"Rota '{nome_rota}': {self.rotas[nome_rota]}\")\n",
        "        else:\n",
        "            print(f\"A rota '{nome_rota}' não foi encontrada.\")\n",
        "\n",
        "    # reseta todas as rotas cadastradas, limpandno o dicionário 'rotas'\n",
        "    def resetar_rotas(self):\n",
        "        self.rotas = {}\n",
        "        # print(\"Todas as rotas foram resetadas.\")\n",
        "\n",
        "    # move o agente aleatoriamente dentro do gridworld e atualiza a rota\n",
        "    # correspondente.\n",
        "    def mover_aleatoriamente(self, nome_rota):\n",
        "        if nome_rota not in self.rotas:\n",
        "            print(f\"A rota '{nome_rota}' não existe.\")\n",
        "            return\n",
        "        # seleciona uma ação aleatória dentro do conjunto de ações possíveis do agente\n",
        "        acao = random.choice(self.agente.obter_acoes())\n",
        "\n",
        "        # move o agente com a ação aleatória escolhida\n",
        "        self.agente.mover(acao, self.gridworld)\n",
        "\n",
        "        # adiciona a nova posição do agente a rota.\n",
        "        # obs: caso a ação tomada leve o agente a posição de uma montanha,\n",
        "        # ele permacenerá na mesma posição e será adicionado na lista da rota\n",
        "        # a coordenada atual dele\n",
        "        self.atualizar_rota(nome_rota)\n",
        "\n",
        "    # gera uma rota aleatória que termina quando atinge-se um máximo de movimentos\n",
        "    # ou quando o agente chega ao ponto de chegada\n",
        "    def gerar_rota_aleatoria(self, nome_rota, max_movimentos=100):\n",
        "        self.agente.posicao = self.agente.inicio_pos\n",
        "\n",
        "        # cadastra a rota\n",
        "        if nome_rota not in self.rotas:\n",
        "            self.cadastrar_rota(nome_rota)\n",
        "\n",
        "        movimentos = 0\n",
        "        # enquanto o agente ainda poder se movimentar\n",
        "        while movimentos < max_movimentos:\n",
        "            # o agente move-se de maneira aleatória\n",
        "            self.mover_aleatoriamente(nome_rota)\n",
        "            # se a nova posição do agente após a ação for o ponto de chegada\n",
        "            # encerra-se a execução e retorna-se o número de movimentos realizados\n",
        "            if self.agente.obter_posicao() == self.gridworld.chegada:\n",
        "                # print(f\"Chegada alcançada em {movimentos + 1} movimentos na rota '{nome_rota}'.\")\n",
        "                self.agente.posicao = self.agente.inicio_pos\n",
        "                return movimentos\n",
        "            movimentos += 1\n",
        "\n",
        "        # print(\"Limite de movimentos atingido.\")\n",
        "        self.agente.posicao = self.agente.inicio_pos\n",
        "        return movimentos\n",
        "\n",
        "    def definicao_valores_estados(self, fator_desconto, num_iteracoes=100):\n",
        "      # matriz para armazenar o valor estimado para cada estado no grid.\n",
        "      # inicialmente todos os valores são 0\n",
        "      valores = [[0 for _ in range(len(self.gridworld.grid[0]))] for _ in range(len(self.gridworld.grid))]\n",
        "\n",
        "      for _ in range(num_iteracoes):\n",
        "          # matriz criada a cada iteração para armazenar os valores atualizados dos estados\n",
        "          valores_atualizados = [[0 for _ in range(len(self.gridworld.grid[0]))] for _ in range(len(self.gridworld.grid))]\n",
        "\n",
        "          # define-se o valor do estado de chegada coomo sendo sua recompensa direta\n",
        "          # sem nenhum desconto aplicado\n",
        "          x_chegada, y_chegada = self.gridworld.chegada\n",
        "          valores_atualizados[y_chegada][x_chegada] = self.gridworld.recompensas[y_chegada][x_chegada]\n",
        "\n",
        "          # iteração em todos os estados (posições no grid)\n",
        "          for y in range(len(self.gridworld.grid)):\n",
        "              for x in range(len(self.gridworld.grid[0])):\n",
        "                  # se a posição atual for a posição de chegada, não deseja-se realizar nenhuma alteraçõa\n",
        "                  # pois o valor dessa posição já foi definido como sua recompensa\n",
        "                  if (x, y) == self.gridworld.chegada:\n",
        "                      continue\n",
        "\n",
        "                  # se a posição atual for uma montenha ou areia movedição, o valor do estado é 0,\n",
        "                  # o que reflete o fato de querermos que o agente não vá para esses estados\n",
        "                  if self.gridworld.grid[y][x] == -1 or self.gridworld.grid[y][x] == -2:\n",
        "                      valores_atualizados[y][x] = 0\n",
        "\n",
        "                  else:\n",
        "                      # defini-se o valor máximo\n",
        "                      valor_maximo_vizinho = float('-inf')\n",
        "\n",
        "                      # para cada ação possível do agente:\n",
        "                      # 1. calcula-se a nova posição (novo_x, novo_y) resultante da ação\n",
        "                      # 2. verifica-se se a nova posição está dentro dos limites do grid\n",
        "                      # 3. se a nova posições estiver dentro dos limites, calcula-se o valor\n",
        "                      # descontado do estado vizinho\n",
        "                      # 4. compara-se o valor descontado do estado vizinho com o valor máximo já\n",
        "                      # encontrado para o vizinho\n",
        "                      for acao, (dx, dy) in self.agente.acoes.items():\n",
        "                          novo_x, novo_y = x + dx, y + dy\n",
        "                          if 0 <= novo_x < len(self.gridworld.grid[0]) and 0 <= novo_y < len(gridworld.grid):\n",
        "                              valor_vizinho = fator_desconto * valores[novo_y][novo_x]\n",
        "                              valor_maximo_vizinho = max(valor_maximo_vizinho, valor_vizinho)\n",
        "\n",
        "                      valores_atualizados[y][x] = valor_maximo_vizinho\n",
        "\n",
        "          # atualização da matriz com os valores de cada estado, após cada iteração\n",
        "          valores = valores_atualizados\n",
        "\n",
        "      return valores\n",
        "\n",
        "    def gerar_rota_inteligente(self, nome_rota, valores_estados):\n",
        "        # registr a a nova rota\n",
        "        self.cadastrar_rota(nome_rota)\n",
        "\n",
        "        movimentos = 0\n",
        "        # enquanto o agente ainda poder se movimentar\n",
        "        while movimentos < 100:\n",
        "            # obtem a posição atual do agente\n",
        "            posicao_atual = self.agente.obter_posicao()\n",
        "            x, y = posicao_atual\n",
        "\n",
        "            # se a posição atual for a posição de chegada,\n",
        "            # encerra a execução\n",
        "            if posicao_atual == self.gridworld.chegada:\n",
        "                print(f\"Chegada alcançada em {movimentos} movimentos na rota '{nome_rota}'.\")\n",
        "                self.agente.posicao = self.agente.inicio_pos\n",
        "                return\n",
        "\n",
        "\n",
        "            melhor_acao = None\n",
        "            melhor_valor = float('-inf')\n",
        "\n",
        "            # itera em cada possível ação definida no agente, calculando a nova\n",
        "            # posição que resultaria dessa ação e verificando se essa nova posição\n",
        "            # é válida. para cada posição válida, pega o valor de estado dessa posição\n",
        "            # e verifica se ele é maior do que o maior valor encontrado até o momento.\n",
        "            # se for, atualiza o maior valor.\n",
        "            for acao, (dx, dy) in self.agente.acoes.items():\n",
        "                novo_x, novo_y = x + dx, y + dy\n",
        "                if 0 <= novo_x < len(self.gridworld.grid[0]) and 0 <= novo_y < len(self.gridworld.grid):\n",
        "                    valor_vizinho = valores_estados[novo_y][novo_x]\n",
        "                    if valor_vizinho > melhor_valor:\n",
        "                        melhor_acao = acao\n",
        "                        melhor_valor = valor_vizinho\n",
        "\n",
        "            # se a melhor ação (a que proporciona ir para um estado com maior valor) for encontrada\n",
        "            # então toma essa ação\n",
        "            if melhor_acao:\n",
        "                self.agente.mover(melhor_acao, self.gridworld)\n",
        "                self.atualizar_rota(nome_rota)\n",
        "            else:\n",
        "                print(\"Não foi possível encontrar uma ação válida. Reiniciando...\")\n",
        "                self.agente.posicao = self.agente.inicio_pos\n",
        "\n",
        "            movimentos += 1\n",
        "\n",
        "        print(\"Limite de movimentos atingido.\")\n",
        "        self.agente.posicao = self.agente.inicio_pos"
      ],
      "metadata": {
        "id": "MNmc-T00sBLx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Execução principal"
      ],
      "metadata": {
        "id": "gUxQGImWZm5F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Definição gridworld"
      ],
      "metadata": {
        "id": "i4vpis3UZwC_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gridworld = Gridworld(8, 8)"
      ],
      "metadata": {
        "id": "IGpK-I5FZ1J7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Definição dos pontos de inicio e fim"
      ],
      "metadata": {
        "id": "ogAy3oPvZqx3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inicio = (0, 0)\n",
        "chegada = (7, 6)\n",
        "\n",
        "gridworld.definir_inicio_chegada(inicio, chegada)"
      ],
      "metadata": {
        "id": "-l-nEsOHZvGu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Definição dos obstáculos"
      ],
      "metadata": {
        "id": "uPUhwEdRZ5qj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "coordenadas_montanhas = [(0, 1), (3, 4), (3, 7)]\n",
        "coordenadas_areias = [(0, 5), (5, 5), (7, 2)]\n",
        "\n",
        "gridworld.definir_obstaculos(coordenadas_montanhas, coordenadas_areias)"
      ],
      "metadata": {
        "id": "tgPmRS9uZ7wc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Definição das recompensas"
      ],
      "metadata": {
        "id": "FaZjfi_KZ-e_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "recompensa_montanha = -1\n",
        "recompensa_areia = -1\n",
        "recompensa_padrao = 0\n",
        "recompensa_chegada = 1\n",
        "\n",
        "gridworld.definir_recompensas(recompensa_chegada, recompensa_areia, recompensa_montanha, recompensa_padrao)"
      ],
      "metadata": {
        "id": "6WFkevKKaASW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Definição do agente"
      ],
      "metadata": {
        "id": "MAX-FYb1aEme"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "agente = Agente(inicio)"
      ],
      "metadata": {
        "id": "5qN-BNMVaKaw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualização do grid"
      ],
      "metadata": {
        "id": "BxfV7jRsaLr0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Modo símbolos"
      ],
      "metadata": {
        "id": "U7Rv8-zPaN9W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gridworld.visualizar_grid(modo=\"simbolos\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n1w9mrk5aPKn",
        "outputId": "6bab367a-9eec-47a0-f44c-a7d4504cf28c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " I |   |   |   |   |   |   |   |\n",
            "--------------------------------\n",
            " M |   |   |   |   |   |   |   |\n",
            "--------------------------------\n",
            "   |   |   |   |   |   |   | A |\n",
            "--------------------------------\n",
            "   |   |   |   |   |   |   |   |\n",
            "--------------------------------\n",
            "   |   |   | M |   |   |   |   |\n",
            "--------------------------------\n",
            " A |   |   |   |   | A |   |   |\n",
            "--------------------------------\n",
            "   |   |   |   |   |   |   | C |\n",
            "--------------------------------\n",
            "   |   |   | M |   |   |   |   |\n",
            "--------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Modo recompensas"
      ],
      "metadata": {
        "id": "D98ONNqdaQVk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gridworld.visualizar_grid(modo=\"recompensas\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "28QqMfVEaTzW",
        "outputId": "a6838eb5-9810-4de5-908b-47ad62f13d3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  0 |  0 |  0 |  0 |  0 |  0 |  0 |  0 |\n",
            "----------------------------------------\n",
            " -1 |  0 |  0 |  0 |  0 |  0 |  0 |  0 |\n",
            "----------------------------------------\n",
            "  0 |  0 |  0 |  0 |  0 |  0 |  0 | -1 |\n",
            "----------------------------------------\n",
            "  0 |  0 |  0 |  0 |  0 |  0 |  0 |  0 |\n",
            "----------------------------------------\n",
            "  0 |  0 |  0 | -1 |  0 |  0 |  0 |  0 |\n",
            "----------------------------------------\n",
            " -1 |  0 |  0 |  0 |  0 | -1 |  0 |  0 |\n",
            "----------------------------------------\n",
            "  0 |  0 |  0 |  0 |  0 |  0 |  0 |  1 |\n",
            "----------------------------------------\n",
            "  0 |  0 |  0 | -1 |  0 |  0 |  0 |  0 |\n",
            "----------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " ## Definição do gerador de rotas"
      ],
      "metadata": {
        "id": "FlUkTBFRaVtl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gerador_rotas = GeradorRotas(gridworld, agente)"
      ],
      "metadata": {
        "id": "DWVCIJQlai2c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Geração de rotas aleatórias"
      ],
      "metadata": {
        "id": "l4nps7VialUN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gerando 100 rotas aleatórias para comparar quantos movimentos em média leva-se para o agente chegar até o ponto de chegada a partir do ponto de início definidos.\n",
        "Os prints de cada rota foram comentados, pois eles servem apenas para debug, podendo ser ignorados para o objetivo dessa análise. Caso deseje visualizar os prints, basta descomentá-los na classe Agente e GeradorRotas"
      ],
      "metadata": {
        "id": "GOQy_vF9aqHs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_movimentos = []\n",
        "num_experimentos = 100\n",
        "maximo_movimentos_permitido = 10**4 # define que o agente pode percorrer no máximo 10000 movimentos\n",
        "\n",
        "for _ in range(num_experimentos):\n",
        "  qtd_movimentos = gerador_rotas.gerar_rota_aleatoria(\"rota_aleatoria\", maximo_movimentos_permitido)\n",
        "  num_movimentos.append(qtd_movimentos)\n",
        "  gerador_rotas.resetar_rotas()"
      ],
      "metadata": {
        "id": "qG-rYrwEa6FM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.mean(num_movimentos)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d9JvJSMebwjM",
        "outputId": "ca4561d9-6045-4a61-8bb8-c1221df80a1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1225.14"
            ]
          },
          "metadata": {},
          "execution_count": 414
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Em média, de maneira aleatória, o agente precisa realziar 1225 movimentos para chegar ao ponto (7,6), saindo do ponto (0,0)."
      ],
      "metadata": {
        "id": "C1Ye0XBnccml"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Geração de rotas com base nos valores de estado"
      ],
      "metadata": {
        "id": "M-aoBDCccmks"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Definindo e visualizando os valores de estado"
      ],
      "metadata": {
        "id": "3mPSEzzbdDlG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "valores_estado = gerador_rotas.definicao_valores_estados(fator_desconto=0.9)"
      ],
      "metadata": {
        "id": "mVUegYEQcqIW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for linha in valores_estado:\n",
        "    for valor in linha:\n",
        "        print(\"{:.2f}\".format(valor), end=\" \")\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FHh5opQmc3Z8",
        "outputId": "8a97f351-0b85-4e79-eccf-ee43c93db4be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.25 0.28 0.31 0.35 0.39 0.43 0.48 0.43 \n",
            "0.00 0.31 0.35 0.39 0.43 0.48 0.53 0.48 \n",
            "0.31 0.35 0.39 0.43 0.48 0.53 0.59 0.00 \n",
            "0.35 0.39 0.43 0.48 0.53 0.59 0.66 0.73 \n",
            "0.39 0.43 0.48 0.00 0.59 0.66 0.73 0.81 \n",
            "0.00 0.48 0.53 0.59 0.66 0.00 0.81 0.90 \n",
            "0.48 0.53 0.59 0.66 0.73 0.81 0.90 1.00 \n",
            "0.43 0.48 0.53 0.00 0.66 0.73 0.81 0.90 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Gerando rota inteligente"
      ],
      "metadata": {
        "id": "QGivbDp_c-Kk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gerador_rotas.gerar_rota_inteligente(\"rota_inteligente\", valores_estado)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g3vbDkhZdIV9",
        "outputId": "b488e9ce-30e9-4438-d951-eed7af0bdc73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chegada alcançada em 13 movimentos na rota 'rota_inteligente'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gerador_rotas.exibir_rota(\"rota_inteligente\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_qokBucCdNv8",
        "outputId": "d145c69a-1d0e-4a59-e42d-dd953c13ae24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rota 'rota_inteligente': [(0, 0), (1, 0), (1, 1), (1, 2), (1, 3), (1, 4), (1, 5), (1, 6), (2, 6), (3, 6), (4, 6), (5, 6), (6, 6), (7, 6)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Com a rota inteligente, que é baseamente na tomada da ação que leva a um estado com maior valor, o agente precisa de apenas 13 movimentos para chegar no ponto (7, 6), partindo do ponto (0, 0)."
      ],
      "metadata": {
        "id": "eOIuSm3WdUaF"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "Bv7FBW5WZZJg"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}